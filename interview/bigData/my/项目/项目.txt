这一个项目是什么，这个项目你负责了什么

介绍自己，讲讲自己的项目？

你解决什么难题

项目架构图

1.各个软件的版本号？
2.spark程序用什么语言写的？
3.用Python写的什么？

大数据平台：
实时推荐系统：
1.项目流程,机器学习的项目流程,电商项目的数据流程？
2.你们一个work给分配多少资源？怎么分配的,预先分配吗?
3.怎么收集的数据？
4.你项目都负责哪一块？
5.推荐系统建模周期,这期间遇到过什么问题？
6.sample正负例样本表，标签是怎么打的？
7.数据来源是什么？
8.标签值是不是不多？（正负例样本表是标签+-1），他指的标签是维度
11.项目数据量，机器学习的项目肯定不大？
12.模型auc直多大0.92，他说挺大，我说我调的准，混淆矩阵相关算法，怎么算的？
13.还有服务器多少台?
14.介绍最近的项目？
a.什么是协同过滤，
b.协同过滤的值怎么求得，
c.hive的调优，
d.具体的pv/uv量，
e.训练数据量，
f.有多少个维度，	
g.特征怎么选取的，
h.模型效果怎么评估）
15.另一个项目问到了数据怎么收集的？
16.埋点怎么弄？
17.你具体负责哪一块？
18.剩下的俩项目你选个讲吧？
19.推荐系统那一套？负例少，正例多怎么办？
20.对自己每个项目做讲解，项目中的疑难点？
21.服务器如何选择？项目服务器多少台？namenode多少台？dotanode多少台？kafka多少台？yarn多少台？
22.讲解自己的项目，遇到的问题？
23.问我数据量多大问题，和mapreduce运行时间问题，由于我实现没有准备好，回答不好，订单的我回答50G，微博我回答1TB，mapreduce运行时间我回答 1~2小时？
24.的推荐系统矩阵列表是怎么实现的?
25.你日志处理具体怎么写的mapreduce  流程?
26.storm 项目中遇到了那些问题，怎么解决？
27.用到hbase的项目提问，实际如何处理的，java是怎么调用的，数据太多怎么优化，你所设定的数据要处理多久?
28.如何搭建实时日志分析平台，需要那些条件？
29.从设计架构，业务实现，为什么这样做，性能如何，等等问题，很多地方深入到项目中实现细节？
30.训练集和测试集的比例多大？
31.描述一下逻辑回归的特点?
32.说说项目中用到的框架？
33.项目里的业务啥的谈了谈？
34.两个项目电信和交通厅，分别用了什么架构，怎么搞得，参与搭建了吗？
35.接着又问flume几台，怎么从其他系统获取的数据，kafka几台？
我说的kafka吞吐量10万条信息每秒，我们用了一台，接着问那一台kafka挂了呢？
36.这个地方回答的不好，没搞过kafka高可用，说多台kafka也是坑，到处都是陷阱。
37.项目中那块是你做的？我说的storm实时通话分析那里，问storm怎么从kafka里读数据的
接着又问storm的spout几台，我说一个，接着说spout挂了怎么办？实在没法回答这些破问题，根本都没遇到过，吹的话那继续深入的问，一堆坑。
38.storm处理完数据写入哪里？回答hdfs和hbase   又问storm怎么写入hdfs和hbase的具体说一下。
39.问我交通厅项目主要做了哪些部分？我说spark MLlib预测路况那部分，问用的什么算法，我说逻辑线性回归
40.接着问线性回归的原理，什么场景适合线性回归，举两个例子说下。
41.模型生成完以后是怎么知道预测的好坏的？
42.对了还问了storm处理的时候利用率怎么样？怎么检测storm没有问题的，程序跑通就一定没有问题吗？反正我也不知道怎么回答了，不知道大数据有没有测试人员，怎么测试改需求?
43.自我介绍，然后就项目，电信项目我主要做了那一块？我说strom实时通话分析那块?
44.怎么从其他系统获取的数据，回答flume+kafka+storm这样的流程。
45.接着问flume有几台，通过什么协议获取的数据，然后就开始开火了?
46.flume收集信息的时候遇到了什么问题？怎么解决的？
47.kafka几台，我回答一台，因为kafka最大支持吞吐量10万条每秒，接着问你们kafka传输的实际吞吐量是多少条每秒，一直追问这个，我没遇到过真不知道怎么回答，kafka传输数据的时候遇到什么错误吗？怎么解决的？又是坑，说没有遇到过。接着又问你们kafka处理的时候都没遇到过什么问题吗？弄得我无言以对，沉默。
48.日志表中的数据使用hive怎么实现，mapreduce怎么实现？题目见附件？
49.你在项目中使用的技术，解决了什么问题？
50.在你做的项目中所使用到得技术或者工具，都是做什么的？
51.flume在实际项目里面的数据采集？
52.感觉自己工作里面做的最好的是哪一块？
53：关于集群数据量，运行时间的参考
刚才面试面试官问了你们每天有多少数据，
用了多少台机器，
一般根据你写的项目，每天产生的数据量规划，假如一天数据量100g
一般集群 规划是年数据的3倍，还有 hadoop集群3倍冗余
假如一台服务器磁盘6T
100G*365*3*3/6*1024g=53.4  这样的集群（一般在60台左右的服务器）
机器的配置，
配置 cpu 找一个稍微老一点至强cpu
内存每台16g或32g
每天运行多久
一般一个作业10分钟到-几个小时不等
一般一个作业也就几十分钟。。运行几天的很少
有多少个MR，
30-50个左右
一般公司很多个作业。。
你可以你们部门的,其他你不清楚就别说，比如数据清洗的（这里面就有很多作业了，去掉不完整数据，数据格式转换，数据字段连接，字段抽取等等），相应你简历上写的项目，，很多模板都有作业。。你细化一下
比如推荐的作业，统计汇总的作业，用户定位的作业，
遇到bug怎么解决，上线之后的bug怎么解决，
一般在测试阶段就那部分线上数据测试过了。。
如果在线上还有问题
一般kill掉作业。。当然可以做mapreduce里面设计日志输出到单独文件，，
根据hadoop异常日志出什么问题了。。当然hadoop每台都会有日志，当然hadoop自己的日子很庞大，，可以采用chukwa（大概看看干什么的就行，就是收集方便查看hadoop本身的日志）处理，
然后分析作业代码。。
有没有关心过运行时候的状态，
mapreduce运行状态，，hadoop有监控页面
当然也可以自己写监控程序，，mapreduce有作业监听方法，可以获取进度。。
http://m.blog.csdn.net/blog/u014313009/38045435

51.自己熟悉大数据的部分说一下？

56。问到了最擅长那种技术？
57.问到了在实际开发的过程中遇到了什么问题？
28.你的集群多大 每天流量多少？
29.你集群中定时任务是怎么做的？
62.是否参加过CodeReview？有什么心得？